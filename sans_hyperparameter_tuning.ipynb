{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SANS Hyperparameter Tuning and Analysis Notebook\n",
    "\n",
    "This comprehensive notebook provides:\n",
    "1. **Hyperparameter grid search** for SANS (Self-Adversarial Negative Sampling)\n",
    "2. **Real-time monitoring** of training metrics and SANS behavior\n",
    "3. **Comparative analysis** across different configurations\n",
    "4. **Debugging visualizations** for understanding SANS dynamics\n",
    "\n",
    "## Key Features:\n",
    "- Automated experiment management\n",
    "- Live training visualization\n",
    "- SANS correlation debugging\n",
    "- Energy distribution analysis\n",
    "- Optimal hyperparameter identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Google Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab\")\n",
    "    # Mount Google Drive for persistent storage\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Set working directory\n",
    "    import os\n",
    "    WORK_DIR = '/content/drive/MyDrive/sans_experiments'\n",
    "    os.makedirs(WORK_DIR, exist_ok=True)\n",
    "    os.chdir(WORK_DIR)\n",
    "else:\n",
    "    print(\"Running locally\")\n",
    "    import os\n",
    "    WORK_DIR = os.getcwd()\n",
    "\n",
    "print(f\"Working directory: {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q accelerate ema-pytorch einops tabulate tqdm matplotlib seaborn pandas plotly ipywidgets\n",
    "print(\"✓ Dependencies installed\")\n",
    "\n",
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import itertools\n",
    "\n",
    "# Import data science libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU detection and optimization\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"Memory: {gpu_memory:.2f} GB\")\n",
    "    \n",
    "    # Set optimal batch size based on GPU\n",
    "    if 'T4' in gpu_name:\n",
    "        DEFAULT_BATCH_SIZE = 256\n",
    "    elif 'V100' in gpu_name:\n",
    "        DEFAULT_BATCH_SIZE = 512\n",
    "    elif 'A100' in gpu_name:\n",
    "        DEFAULT_BATCH_SIZE = 1024\n",
    "    else:\n",
    "        DEFAULT_BATCH_SIZE = 128\n",
    "else:\n",
    "    print(\"⚠ No GPU detected - training will be slow\")\n",
    "    DEFAULT_BATCH_SIZE = 32\n",
    "\n",
    "print(f\"\\nDefault batch size: {DEFAULT_BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone or update the repository\n",
    "REPO_DIR = Path(WORK_DIR) / 'energy-based-model'\n",
    "\n",
    "if not REPO_DIR.exists():\n",
    "    print(\"Cloning repository...\")\n",
    "    !rm -rf energy-based-model\n",
    "    !git clone https://github.com/mdkrasnow/energy-based-model.git\n",
    "else:\n",
    "    print(\"Repository exists, pulling latest changes...\")\n",
    "    os.chdir(REPO_DIR)\n",
    "    !git pull\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "sys.path.insert(0, str(REPO_DIR))\n",
    "\n",
    "# Import project modules\n",
    "from utils.sans_analysis import (\n",
    "    load_sans_metrics,\n",
    "    analyze_correlation_quality,\n",
    "    analyze_entropy_dynamics,\n",
    "    analyze_energy_separation,\n",
    "    plot_sans_diagnostics,\n",
    "    compare_sans_configurations,\n",
    "    generate_hyperparameter_report\n",
    ")\n",
    "\n",
    "print(f\"✓ Repository ready at {REPO_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid for SANS\n",
    "HYPERPARAMETER_GRID = {\n",
    "    'sans_num_negs': [4, 8, 16, 32, 64],  # Number of negative samples\n",
    "    'sans_temp': [0.5, 1.0, 1.5, 2.0],     # Temperature parameter\n",
    "    'sans_temp_schedule': [True, False],   # Temperature scheduling\n",
    "}\n",
    "\n",
    "# Fixed parameters for all experiments\n",
    "FIXED_PARAMS = {\n",
    "    'dataset': 'inverse',\n",
    "    'model': 'mlp',\n",
    "    'rank': 20,\n",
    "    'batch_size': DEFAULT_BATCH_SIZE,\n",
    "    'diffusion_steps': 10,\n",
    "    'max_steps': 10000,  # Reduced for quick experiments\n",
    "    'supervise_energy_landscape': True,\n",
    "    'sans': True,\n",
    "    'sans_debug': True,\n",
    "    'data_workers': 2\n",
    "}\n",
    "\n",
    "# Task-specific configurations\n",
    "TASK_CONFIGS = {\n",
    "    'inverse': {\n",
    "        'dataset': 'inverse',\n",
    "        'rank': 20,\n",
    "        'metric': 'mse'\n",
    "    },\n",
    "    'sudoku': {\n",
    "        'dataset': 'sudoku-rrn',\n",
    "        'model': 'sudoku',\n",
    "        'metric': 'sudoku',\n",
    "        'cond_mask': True,\n",
    "        'batch_size': 64\n",
    "    },\n",
    "    'connectivity': {\n",
    "        'dataset': 'connectivity',\n",
    "        'model': 'gnn-conv-1d-v2',\n",
    "        'metric': 'bce',\n",
    "        'batch_size': 64\n",
    "    }\n",
    "}\n",
    "\n",
    "# Select task\n",
    "SELECTED_TASK = 'inverse'  # Change this to switch tasks\n",
    "print(f\"Selected task: {SELECTED_TASK}\")\n",
    "\n",
    "# Update fixed params with task-specific config\n",
    "if SELECTED_TASK in TASK_CONFIGS:\n",
    "    FIXED_PARAMS.update(TASK_CONFIGS[SELECTED_TASK])\n",
    "\n",
    "# Generate all experiment configurations\n",
    "def generate_experiment_configs():\n",
    "    \"\"\"Generate all combinations of hyperparameters.\"\"\"\n",
    "    configs = []\n",
    "    \n",
    "    # Get all combinations\n",
    "    keys = list(HYPERPARAMETER_GRID.keys())\n",
    "    values = [HYPERPARAMETER_GRID[k] for k in keys]\n",
    "    \n",
    "    for combo in itertools.product(*values):\n",
    "        config = FIXED_PARAMS.copy()\n",
    "        for i, key in enumerate(keys):\n",
    "            config[key] = combo[i]\n",
    "        \n",
    "        # Create experiment name\n",
    "        exp_name = f\"sans_K{config['sans_num_negs']}_T{config['sans_temp']}\"\n",
    "        if config['sans_temp_schedule']:\n",
    "            exp_name += \"_sched\"\n",
    "        \n",
    "        configs.append((exp_name, config))\n",
    "    \n",
    "    return configs\n",
    "\n",
    "EXPERIMENT_CONFIGS = generate_experiment_configs()\n",
    "print(f\"Total experiments to run: {len(EXPERIMENT_CONFIGS)}\")\n",
    "\n",
    "# Add baseline configuration (no SANS)\n",
    "baseline_config = FIXED_PARAMS.copy()\n",
    "baseline_config['sans'] = False\n",
    "baseline_config['supervise_energy_landscape'] = False\n",
    "EXPERIMENT_CONFIGS.insert(0, ('baseline_no_sans', baseline_config))\n",
    "\n",
    "print(f\"\\nFirst 5 experiment names:\")\n",
    "for name, _ in EXPERIMENT_CONFIGS[:5]:\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiment Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentManager:\n",
    "    \"\"\"Manages running and tracking experiments.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_dir: str = 'experiments'):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.base_dir.mkdir(exist_ok=True)\n",
    "        self.experiments_file = self.base_dir / 'experiments.json'\n",
    "        self.load_experiments()\n",
    "    \n",
    "    def load_experiments(self):\n",
    "        \"\"\"Load existing experiments from file.\"\"\"\n",
    "        if self.experiments_file.exists():\n",
    "            with open(self.experiments_file, 'r') as f:\n",
    "                self.experiments = json.load(f)\n",
    "        else:\n",
    "            self.experiments = {}\n",
    "    \n",
    "    def save_experiments(self):\n",
    "        \"\"\"Save experiments to file.\"\"\"\n",
    "        with open(self.experiments_file, 'w') as f:\n",
    "            json.dump(self.experiments, f, indent=2)\n",
    "    \n",
    "    def run_experiment(self, name: str, config: dict, force: bool = False):\n",
    "        \"\"\"Run a single experiment.\"\"\"\n",
    "        \n",
    "        # Check if already run\n",
    "        if name in self.experiments and not force:\n",
    "            print(f\"Experiment '{name}' already exists. Skipping...\")\n",
    "            return self.experiments[name]\n",
    "        \n",
    "        # Create experiment directory\n",
    "        exp_dir = self.base_dir / name\n",
    "        exp_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save configuration\n",
    "        config_file = exp_dir / 'config.json'\n",
    "        with open(config_file, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n",
    "        \n",
    "        # Build command\n",
    "        cmd = ['python', 'train.py']\n",
    "        for key, value in config.items():\n",
    "            if key == 'results_dir':\n",
    "                continue\n",
    "            cmd.append(f'--{key.replace(\"_\", \"-\")}')\n",
    "            if not isinstance(value, bool):\n",
    "                cmd.append(str(value))\n",
    "            elif value is False:\n",
    "                cmd[-1] = f'--no-{key.replace(\"_\", \"-\")}'\n",
    "        \n",
    "        # Add results directory\n",
    "        results_dir = str(exp_dir / 'results')\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        # Export configuration\n",
    "        cmd.extend(['--export-config', 'experiment_config'])\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Running experiment: {name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Command: {' '.join(cmd)}\")\n",
    "        print(f\"Results directory: {results_dir}\")\n",
    "        \n",
    "        # Run training\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Change to repo directory for running\n",
    "        original_dir = os.getcwd()\n",
    "        os.chdir(REPO_DIR)\n",
    "        \n",
    "        try:\n",
    "            # Run with output capture\n",
    "            process = subprocess.Popen(\n",
    "                cmd,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                universal_newlines=True,\n",
    "                env={**os.environ, 'RESULTS_FOLDER': results_dir}\n",
    "            )\n",
    "            \n",
    "            # Stream output\n",
    "            for line in process.stdout:\n",
    "                print(line, end='')\n",
    "            \n",
    "            process.wait()\n",
    "            success = process.returncode == 0\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error running experiment: {e}\")\n",
    "            success = False\n",
    "        finally:\n",
    "            os.chdir(original_dir)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        # Record experiment\n",
    "        self.experiments[name] = {\n",
    "            'config': config,\n",
    "            'start_time': start_time,\n",
    "            'end_time': end_time,\n",
    "            'duration': duration,\n",
    "            'success': success,\n",
    "            'results_dir': results_dir\n",
    "        }\n",
    "        \n",
    "        self.save_experiments()\n",
    "        \n",
    "        print(f\"\\nExperiment '{name}' completed in {duration:.1f} seconds\")\n",
    "        return self.experiments[name]\n",
    "    \n",
    "    def run_all_experiments(self, configs: list, parallel: bool = False):\n",
    "        \"\"\"Run all experiments from configuration list.\"\"\"\n",
    "        \n",
    "        for name, config in configs:\n",
    "            self.run_experiment(name, config)\n",
    "            \n",
    "            # Add small delay between experiments\n",
    "            time.sleep(2)\n",
    "    \n",
    "    def get_results_paths(self) -> dict:\n",
    "        \"\"\"Get paths to all experiment results.\"\"\"\n",
    "        paths = {}\n",
    "        for name, exp in self.experiments.items():\n",
    "            if exp.get('success'):\n",
    "                paths[name] = exp['results_dir']\n",
    "        return paths\n",
    "\n",
    "# Create experiment manager\n",
    "exp_manager = ExperimentManager(base_dir=f'experiments_{SELECTED_TASK}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}')\n",
    "print(f\"Experiment manager initialized at: {exp_manager.base_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Run a single test experiment\n",
    "test_config = EXPERIMENT_CONFIGS[0]\n",
    "print(f\"Running test experiment: {test_config[0]}\")\n",
    "print(f\"Configuration: {json.dumps(test_config[1], indent=2)}\")\n",
    "\n",
    "# Reduce steps for test\n",
    "test_config[1]['max_steps'] = 1000\n",
    "\n",
    "result = exp_manager.run_experiment(test_config[0], test_config[1])\n",
    "print(f\"\\nTest complete: {result['success']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Run all experiments (WARNING: This will take a long time!)\n",
    "# Uncomment to run all experiments\n",
    "\n",
    "# print(f\"Running {len(EXPERIMENT_CONFIGS)} experiments...\")\n",
    "# print(\"This will take several hours. Consider running overnight.\")\n",
    "# \n",
    "# # Confirm before running\n",
    "# confirm = input(\"Are you sure you want to run all experiments? (yes/no): \")\n",
    "# if confirm.lower() == 'yes':\n",
    "#     exp_manager.run_all_experiments(EXPERIMENT_CONFIGS)\n",
    "#     print(\"\\n✓ All experiments complete!\")\n",
    "# else:\n",
    "#     print(\"Cancelled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Real-time Training Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMonitor:\n",
    "    \"\"\"Real-time monitoring of training progress.\"\"\"\n",
    "    \n",
    "    def __init__(self, results_dir: str):\n",
    "        self.results_dir = Path(results_dir)\n",
    "        self.metrics_file = self.results_dir / 'metrics.csv'\n",
    "        self.sans_file = self.results_dir / 'sans_debug.csv'\n",
    "    \n",
    "    def load_current_metrics(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Load current metrics from files.\"\"\"\n",
    "        metrics_df = pd.DataFrame()\n",
    "        sans_df = pd.DataFrame()\n",
    "        \n",
    "        if self.metrics_file.exists():\n",
    "            metrics_df = pd.read_csv(self.metrics_file)\n",
    "        \n",
    "        if self.sans_file.exists():\n",
    "            sans_df = pd.read_csv(self.sans_file)\n",
    "        \n",
    "        return metrics_df, sans_df\n",
    "    \n",
    "    def create_live_dashboard(self):\n",
    "        \"\"\"Create interactive dashboard with Plotly.\"\"\"\n",
    "        \n",
    "        metrics_df, sans_df = self.load_current_metrics()\n",
    "        \n",
    "        if len(metrics_df) == 0:\n",
    "            print(\"No metrics available yet...\")\n",
    "            return\n",
    "        \n",
    "        # Create subplots\n",
    "        fig = make_subplots(\n",
    "            rows=3, cols=3,\n",
    "            subplot_titles=(\n",
    "                'Training Loss', 'Loss Components', 'Learning Rate',\n",
    "                'SANS Correlation', 'Entropy Ratio', 'Energy Separation',\n",
    "                'Temperature Schedule', 'Negative Energy Stats', 'Training Speed'\n",
    "            ),\n",
    "            specs=[[{}, {}, {}],\n",
    "                   [{}, {}, {}],\n",
    "                   [{}, {}, {}]]\n",
    "        )\n",
    "        \n",
    "        # 1. Training Loss\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=metrics_df['step'], y=metrics_df['loss'],\n",
    "                      mode='lines', name='Total Loss',\n",
    "                      line=dict(color='blue')),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # 2. Loss Components\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=metrics_df['step'], y=metrics_df['loss_denoise'],\n",
    "                      mode='lines', name='Denoise',\n",
    "                      line=dict(color='green')),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=metrics_df['step'], y=metrics_df['loss_energy'],\n",
    "                      mode='lines', name='Energy',\n",
    "                      line=dict(color='red')),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # 3. Learning Rate\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=metrics_df['step'], y=metrics_df['lr'],\n",
    "                      mode='lines', name='LR',\n",
    "                      line=dict(color='purple')),\n",
    "            row=1, col=3\n",
    "        )\n",
    "        \n",
    "        # SANS metrics if available\n",
    "        if len(sans_df) > 0:\n",
    "            # 4. SANS Correlation\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=sans_df['step'], y=sans_df['weight_energy_corr'],\n",
    "                          mode='lines', name='Correlation',\n",
    "                          line=dict(color='orange')),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            fig.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\",\n",
    "                         row=2, col=1)\n",
    "            \n",
    "            # 5. Entropy Ratio\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=sans_df['step'], y=sans_df['entropy_ratio'],\n",
    "                          mode='lines', name='Entropy',\n",
    "                          line=dict(color='brown')),\n",
    "                row=2, col=2\n",
    "            )\n",
    "            \n",
    "            # 6. Energy Separation\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=sans_df['step'], y=sans_df['real_energy_mean'],\n",
    "                          mode='lines', name='Real Energy',\n",
    "                          line=dict(color='green')),\n",
    "                row=2, col=3\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=sans_df['step'], y=sans_df['neg_energy_mean'],\n",
    "                          mode='lines', name='Neg Energy',\n",
    "                          line=dict(color='red')),\n",
    "                row=2, col=3\n",
    "            )\n",
    "            \n",
    "            # 7. Temperature Schedule\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=sans_df['step'], y=sans_df['alpha_effective'],\n",
    "                          mode='lines', name='Alpha',\n",
    "                          line=dict(color='purple')),\n",
    "                row=3, col=1\n",
    "            )\n",
    "            \n",
    "            # 8. Negative Energy Stats\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=sans_df['step'], y=sans_df['neg_energy_std'],\n",
    "                          mode='lines', name='Neg Std',\n",
    "                          line=dict(color='cyan')),\n",
    "                row=3, col=2\n",
    "            )\n",
    "        \n",
    "        # 9. Training Speed\n",
    "        if 'time' in metrics_df.columns:\n",
    "            steps_per_sec = metrics_df['step'] / metrics_df['time']\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=metrics_df['step'], y=steps_per_sec,\n",
    "                          mode='lines', name='Steps/sec',\n",
    "                          line=dict(color='black')),\n",
    "                row=3, col=3\n",
    "            )\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=900,\n",
    "            showlegend=False,\n",
    "            title_text=\"Training Dashboard\",\n",
    "            title_font_size=20\n",
    "        )\n",
    "        \n",
    "        # Update axes\n",
    "        fig.update_xaxes(title_text=\"Step\")\n",
    "        fig.update_yaxes(title_text=\"Value\")\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def monitor_live(self, refresh_interval: int = 5):\n",
    "        \"\"\"Monitor training with live updates.\"\"\"\n",
    "        \n",
    "        print(f\"Monitoring: {self.results_dir}\")\n",
    "        print(f\"Refresh interval: {refresh_interval} seconds\")\n",
    "        print(\"Press Ctrl+C to stop monitoring\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                clear_output(wait=True)\n",
    "                \n",
    "                # Load and display current metrics\n",
    "                metrics_df, sans_df = self.load_current_metrics()\n",
    "                \n",
    "                if len(metrics_df) > 0:\n",
    "                    current_step = metrics_df['step'].iloc[-1]\n",
    "                    current_loss = metrics_df['loss'].iloc[-1]\n",
    "                    \n",
    "                    print(f\"Step: {current_step} | Loss: {current_loss:.6f}\")\n",
    "                    \n",
    "                    # Create and show dashboard\n",
    "                    fig = self.create_live_dashboard()\n",
    "                    if fig:\n",
    "                        fig.show()\n",
    "                else:\n",
    "                    print(\"Waiting for training to start...\")\n",
    "                \n",
    "                time.sleep(refresh_interval)\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nMonitoring stopped.\")\n",
    "\n",
    "# Example: Monitor a specific experiment\n",
    "# monitor = TrainingMonitor('experiments_inverse_20231124_120000/baseline_no_sans/results')\n",
    "# monitor.monitor_live(refresh_interval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and compare all experiment results\n",
    "results_paths = exp_manager.get_results_paths()\n",
    "\n",
    "if len(results_paths) > 0:\n",
    "    print(f\"Found {len(results_paths)} completed experiments\")\n",
    "    \n",
    "    # Compare configurations\n",
    "    comparison_df = compare_sans_configurations(results_paths)\n",
    "    \n",
    "    # Display summary\n",
    "    display(comparison_df[['experiment', 'final_loss', 'convergence_step', \n",
    "                           'corr_mean_correlation', 'entropy_mean_entropy_ratio']].head(10))\n",
    "else:\n",
    "    print(\"No completed experiments found. Run experiments first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparative visualizations\n",
    "if len(results_paths) > 1:\n",
    "    # Load metrics for all experiments\n",
    "    all_metrics = {}\n",
    "    for name, path in results_paths.items():\n",
    "        metrics_df, sans_df = load_sans_metrics(path)\n",
    "        all_metrics[name] = {'metrics': metrics_df, 'sans': sans_df}\n",
    "    \n",
    "    # Plot training curves comparison\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Experiment Comparison', fontsize=16)\n",
    "    \n",
    "    for name, data in all_metrics.items():\n",
    "        metrics_df = data['metrics']\n",
    "        sans_df = data['sans']\n",
    "        \n",
    "        if len(metrics_df) > 0:\n",
    "            # Training loss\n",
    "            axes[0, 0].plot(metrics_df['step'], metrics_df['loss'], \n",
    "                           label=name, alpha=0.7)\n",
    "            \n",
    "            # Loss components\n",
    "            axes[0, 1].plot(metrics_df['step'], metrics_df['loss_energy'],\n",
    "                           label=name, alpha=0.7)\n",
    "        \n",
    "        if len(sans_df) > 0:\n",
    "            # SANS correlation\n",
    "            axes[1, 0].plot(sans_df['step'], sans_df['weight_energy_corr'],\n",
    "                           label=name, alpha=0.7)\n",
    "            \n",
    "            # Entropy ratio\n",
    "            axes[1, 1].plot(sans_df['step'], sans_df['entropy_ratio'],\n",
    "                           label=name, alpha=0.7)\n",
    "    \n",
    "    axes[0, 0].set_title('Training Loss')\n",
    "    axes[0, 0].set_xlabel('Step')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_yscale('log')\n",
    "    axes[0, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].set_title('Energy Loss Component')\n",
    "    axes[0, 1].set_xlabel('Step')\n",
    "    axes[0, 1].set_ylabel('Energy Loss')\n",
    "    axes[0, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 0].set_title('SANS Weight-Energy Correlation')\n",
    "    axes[1, 0].set_xlabel('Step')\n",
    "    axes[1, 0].set_ylabel('Correlation')\n",
    "    axes[1, 0].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "    axes[1, 0].axhline(y=-0.3, color='g', linestyle='--', alpha=0.3)\n",
    "    axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 1].set_title('SANS Entropy Ratio')\n",
    "    axes[1, 1].set_xlabel('Step')\n",
    "    axes[1, 1].set_ylabel('Entropy Ratio')\n",
    "    axes[1, 1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter impact heatmap\n",
    "if 'comparison_df' in locals() and len(comparison_df) > 0:\n",
    "    # Extract hyperparameters from experiment names\n",
    "    hp_data = []\n",
    "    for _, row in comparison_df.iterrows():\n",
    "        name = row['experiment']\n",
    "        if 'sans_K' in name:\n",
    "            # Parse SANS hyperparameters\n",
    "            parts = name.split('_')\n",
    "            k_val = int(parts[1][1:])  # Extract K value\n",
    "            t_val = float(parts[2][1:])  # Extract T value\n",
    "            scheduled = 'sched' in name\n",
    "            \n",
    "            hp_data.append({\n",
    "                'K': k_val,\n",
    "                'Temperature': t_val,\n",
    "                'Scheduled': scheduled,\n",
    "                'Final Loss': row.get('final_loss', None),\n",
    "                'Correlation': row.get('corr_mean_correlation', None)\n",
    "            })\n",
    "    \n",
    "    if hp_data:\n",
    "        hp_df = pd.DataFrame(hp_data)\n",
    "        \n",
    "        # Create pivot table for heatmap\n",
    "        pivot_loss = hp_df.pivot_table(\n",
    "            values='Final Loss',\n",
    "            index='Temperature',\n",
    "            columns='K',\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        \n",
    "        # Plot heatmap\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.heatmap(pivot_loss, annot=True, fmt='.4f', cmap='RdYlGn_r',\n",
    "                   cbar_kws={'label': 'Final Loss'})\n",
    "        plt.title('Hyperparameter Impact on Final Loss')\n",
    "        plt.xlabel('Number of Negatives (K)')\n",
    "        plt.ylabel('Temperature (α)')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best Configuration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and analyze best configuration\n",
    "if 'comparison_df' in locals() and len(comparison_df) > 0:\n",
    "    # Find best by final loss\n",
    "    best_idx = comparison_df['final_loss'].idxmin()\n",
    "    best_exp = comparison_df.loc[best_idx]\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"BEST CONFIGURATION FOUND\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Experiment: {best_exp['experiment']}\")\n",
    "    print(f\"Final Loss: {best_exp['final_loss']:.6f}\")\n",
    "    print(f\"Convergence Step: {best_exp.get('convergence_step', 'N/A')}\")\n",
    "    print(f\"Mean Correlation: {best_exp.get('corr_mean_correlation', 'N/A'):.3f}\")\n",
    "    print(f\"Mean Entropy Ratio: {best_exp.get('entropy_mean_entropy_ratio', 'N/A'):.3f}\")\n",
    "    print(f\"Mean Energy Separation: {best_exp.get('energy_mean_separation', 'N/A'):.3f}\")\n",
    "    \n",
    "    # Load and plot detailed diagnostics for best experiment\n",
    "    if best_exp['experiment'] in results_paths:\n",
    "        best_path = results_paths[best_exp['experiment']]\n",
    "        metrics_df, sans_df = load_sans_metrics(best_path)\n",
    "        \n",
    "        if len(sans_df) > 0:\n",
    "            print(\"\\nGenerating detailed SANS diagnostics...\")\n",
    "            fig = plot_sans_diagnostics(sans_df, \n",
    "                                       save_path=f\"{exp_manager.base_dir}/best_diagnostics.png\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive report\n",
    "if len(results_paths) > 0:\n",
    "    report_path = exp_manager.base_dir / 'hyperparameter_report.txt'\n",
    "    report = generate_hyperparameter_report(results_paths, save_path=str(report_path))\n",
    "    \n",
    "    print(report)\n",
    "    print(f\"\\n✓ Report saved to {report_path}\")\n",
    "    \n",
    "    # Save comparison dataframe\n",
    "    csv_path = exp_manager.base_dir / 'comparison_results.csv'\n",
    "    comparison_df.to_csv(csv_path, index=False)\n",
    "    print(f\"✓ Comparison data saved to {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Recommendations and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE - RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "if 'comparison_df' in locals() and len(comparison_df) > 0:\n",
    "    # Analyze results\n",
    "    baseline_loss = comparison_df[comparison_df['experiment'] == 'baseline_no_sans']['final_loss'].values\n",
    "    if len(baseline_loss) > 0:\n",
    "        baseline_loss = baseline_loss[0]\n",
    "        sans_losses = comparison_df[comparison_df['experiment'] != 'baseline_no_sans']['final_loss']\n",
    "        improvement = (baseline_loss - sans_losses.min()) / baseline_loss * 100\n",
    "        \n",
    "        if improvement > 0:\n",
    "            print(f\"✓ SANS shows {improvement:.1f}% improvement over baseline\")\n",
    "        else:\n",
    "            print(f\"⚠ SANS did not improve over baseline in this experiment\")\n",
    "    \n",
    "    # Check correlation quality\n",
    "    mean_corrs = comparison_df['corr_mean_correlation'].dropna()\n",
    "    if len(mean_corrs) > 0:\n",
    "        good_corr_ratio = (mean_corrs < -0.2).mean()\n",
    "        print(f\"\\nCorrelation Quality:\")\n",
    "        print(f\"  - {good_corr_ratio*100:.1f}% of experiments show good negative correlation\")\n",
    "        print(f\"  - Best correlation: {mean_corrs.min():.3f}\")\n",
    "    \n",
    "    print(\"\\nRecommended Hyperparameters:\")\n",
    "    if 'best_exp' in locals():\n",
    "        name = best_exp['experiment']\n",
    "        if 'sans_K' in name:\n",
    "            parts = name.split('_')\n",
    "            print(f\"  - Number of negatives (K): {parts[1][1:]}\")\n",
    "            print(f\"  - Temperature (α): {parts[2][1:]}\")\n",
    "            print(f\"  - Temperature scheduling: {'Yes' if 'sched' in name else 'No'}\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Run longer training with best configuration (50k+ steps)\")\n",
    "print(\"2. Test on more challenging datasets (sudoku, connectivity)\")\n",
    "print(\"3. Fine-tune temperature schedule for your specific task\")\n",
    "print(\"4. Consider adaptive K based on training progress\")\n",
    "print(\"5. Implement curriculum learning with increasing K over time\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTEBOOK COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
